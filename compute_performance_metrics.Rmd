---
title: "compute_metrics"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(sensitivity)
library(tidyverse)
library(purrr)
library(ggpubr)
```
# Comparing model and observed time series output

When evaluating a model - Always plot first

Plotting and what it can tell you

* plot through time 
  * look for differences in performance in different periods
  * does model capture seasonality, temporal trends

* some things to think about that might help make it easier to "see" differences between
observed time series and modelled time series

  * consider appropriate y-axis 
  * consider picking a window (subset in x-axis) 

* plot x-y (observed vs model)
  * look for bias (error) (using a 1 to 1 line are points always above or below)
  * look for errors associated with particular magnitdues (e.g high or low values)
  
```{r simple}
sager = read.table("sager.txt", header=T)
head(sager)

# add date
sager = sager %>% mutate(date = paste(day,month,year, sep="/"))
sager$date = as.Date(sager$date,"%d/%m/%Y")

# plot
sagerl = sager %>% pivot_longer(cols=c("model","obs"), names_to="source",
                                  values_to="flow")

# basic plot
ggplot(sagerl, aes(date, flow, col=source, linetype=source))+geom_line()

# change axis to get a closer look at performance at low values
# when you have high dynamic range (lots of large and small values), taking log can help
# with visualization
ggplot(sagerl, aes(date, flow, col=source, linetype=source))+geom_line()+scale_y_continuous(trans="log")+labs(y="streamflow mm/day")

# look at it another way
ggplot(sager, aes(obs, model))+geom_point()+geom_abline(intercept=0, slope=1, col="red")


```

# Measure Performance using different metrics

Once you've plotted, consider some metrics that summarize performance

Think about what part of the time-series is of interest

  * long term means (bims)
  * year to year variablity
  * peak or minimum events
  
Create performance metrics that are relevant to the model application

Lets start though with some simple metrics

```{r}


source("nse.R")

source("relerr.R")


source("cper.R")

nse
relerr
cper
nse(m=sager$model, o=sager$obs)

relerr(m=sager$model, o=sager$obs)*100

cper(m=sager$model, o=sager$obs, weight.nse=0.8)


```

# Scale and subsetting

Performance also depends on the 'what' you are evaluating

  * time steps (annual, daily, monthly)
  
  * selection of particular periods of time
  
```{r}
# try a different time step
sager_wy = sager %>% group_by(wy) %>% summarize(model=sum(model), obs=sum(obs))

nse(sager_wy$model, sager_wy$obs)
cper(m=sager_wy$model, o=sager_wy$obs, weight.nse=0.8)

# just look at august flow
# first sum by month
tmp = sager %>% group_by(month, year) %>% summarize(model=sum(model), obs=sum(obs))

# now extract august
sager_aug = subset(tmp, month==8)
cor(sager_aug$model, sager_aug$obs)

# turn your evaluation metric into a function
source("compute_lowflowmetrics.R")
compute_lowflowmetrics
compute_lowflowmetrics(m=sager$model,o=sager$obs, month=sager$month, day=sager$day, year=sager$year, wy=sager$wy)

# use different low flow months
compute_lowflowmetrics(m=sager$model,o=sager$obs, month=sager$month, day=sager$day, year=sager$year, wy=sager$wy, low_flow_months = c(7:9))


```
  

# try another metric

```{r}
# turn your evaluation metric into a function
source("compute_highflowmetrics.R")
compute_highflowmetrics
compute_highflowmetrics(m=sager$model,o=sager$obs, month=sager$month, day=sager$day, year=sager$year, wy=sager$wy)

# use different high flow months
compute_highflowmetrics(m=sager$model,o=sager$obs, month=sager$month, day=sager$day, year=sager$year, wy=sager$wy, high_flow_months = c(3:5))
```


# Create a combined metric

Sometime you want to summarize everything in one number

Especially if you want to rank different models
or create indices like Sobol Sensitivity Indices

```{r}

perf = compute_lowflowmetrics(m=sager$model,o=sager$obs, month=sager$month, day=sager$day, year=sager$year, wy=sager$wy, low_flow_months = c(7:9))

perf = as.data.frame((perf))
# remember you want error to be low but correlation to be high 
# so we need to transform in some way

# normalize by max error = if error is greater than this we don't care
# many ideas -  maybe 50% of mean daily summer observed low flow
tmp = sager %>% subset(month %in% c(7:9)) 
errmax = mean(tmp$obs)*0.5

perf = perf %>% mutate(annual_min_err_trans = max(0,(1-abs(annual_min_err/errmax) )))
      
# for monthly we can do a simpler thing to find maximum allowable errror   
tmp = sager %>% subset(month %in% c(7:9)) %>% group_by(wy, month) %>% summarize(obs=sum(obs))


errmax = mean(tmp$obs)*0.5
 
perf = perf %>% mutate(low_month_err_trans = max(0,(1-abs(low_month_err/errmax) )))

# now we have 4 measures that we can combine together

perf = perf %>% mutate(combined = (annual_min_cor + annual_min_err_trans + low_month_err_trans + low_month_cor)/4)
perf
# or weight differently - we know that minimum flows are hard to get to weight those differently

perf = perf %>% mutate(combined2 = 0.1*annual_min_cor + 0.1*annual_min_err_trans + 0.4*low_month_err_trans+ 0.4*low_month_cor)

perf

# easier to put all this in a function
```

## High flow
```{r}
perf_high = compute_highflowmetrics(m=sager$model,o=sager$obs, month=sager$month, day=sager$day, year=sager$year, wy=sager$wy, high_flow_months = c(3:5))

perf_high = as.data.frame((perf_high))
# remember you want error to be low but correlation to be high 
# so we need to transform in some way

# normalize by max error = if error is greater than this we don't care
# many ideas -  maybe 50% of mean daily summer observed low flow
tmp = sager %>% subset(month %in% c(3:5)) 
errmax_high = mean(tmp$obs)*0.5

perf_high = perf_high %>% mutate(annual_max_err_trans = max(0,(1-abs(annual_max_err/errmax_high) )))
      
# for monthly we can do a simpler thing to find maximum allowable errror   
tmp_high = sager %>% subset(month %in% c(3:5)) %>% group_by(wy, month) %>% summarize(obs=sum(obs))

errmax_high = mean(tmp_high$obs)*0.5
 
perf_high = perf_high %>% mutate(high_month_err_trans = max(0,(1-abs(high_month_err/errmax_high) )))

# now we have 4 measures that we can combine together

perf_high = perf_high %>% mutate(combined = (annual_max_cor + annual_max_err_trans + high_month_err_trans + high_month_cor)/4)
perf_high
# or weight differently 

perf_high = perf_high %>% mutate(combined2 = 0.1*annual_max_cor + 0.1*annual_max_err_trans + 0.4*high_month_err_trans+ 0.4*high_month_cor)

perf_high

# easier to put all this in a function
```

# Calibration

Calibration is picking parameter sets based on performance evaluation

Apply metrics over multiple outputs (generated by running across many parameters sets) 

Ideally we'd generate these parameter "smartly" - LHS or Sobol sampling

Example - a dataset where each column
is a different model run for Sagehen Creek
(using different parameters) 

don't worry about what the  parameters are  for now

File Name
* sagerm.txt



```{r multiple}

# multiple results - lets say we've run the model for multiple years, each column
# is streamflow for a different parameter set
msage = read.table("sagerm.txt", header=T)

# lets say we know the start date from our earlier output
msage$date = sager$date
head(msage)
msage$month = sager$month
msage$year = sager$year
msage$day = sager$day
msage$wy = sager$wy

# and we still have observed data from above


# how can we plot all results - lets plot water year 1970 otherwise its hard to see
msagel = msage %>% pivot_longer(cols=!c(date, month, year, day,wy), names_to="run", values_to="flow")

p1=ggplot(subset(msagel, wy == 1970), aes(as.Date(date), flow, col=run))+geom_line()+theme(legend.position = "none")
p1
# lets add observed streamflow
p1+geom_line(data=subset(sager, wy == 1970), aes(as.Date(date), obs), size=2, col="black", linetype=2)+labs(y="Streamflow", x="Date")


# compute performance measures for all output
res = msage %>% select(!c("date","month","year","day","wy")) %>%
      map_dbl(nse, o=sager$obs )

head(res)

# another example using our low flow statistics
# use apply to compute for all the data
# using the updated low flow metrics routing that also computed combined metrics

source("compute_lowflowmetrics_all.R")
res = msage %>% select(-date, -month, -day, -year, -wy ) %>% map_df(compute_lowflowmetrics_all, o=sager$obs, month=msage$month, day=msage$day, year=msage$year, wy=msage$wy)


# interesting to look at range of metrics - could use this to decide on
# acceptable values
summary(res)


# graph range of performance measures
resl = res %>% pivot_longer(cols=everything(), names_to="metric", values_to="value")
ggplot(resl, aes(metric, value))+geom_boxplot()+facet_wrap(~metric, scales="free")

# try this
# assign an identifier to each row, use the same identify for columns of original streamflow data
# we can then use that to pick data
res$run = seq(from=1,to=nrow(res))
head(msage)
colnames(msage)=c(res$run, "date","month","year","day","wy")

# best one
best = res[which.max(res$combined),]
msagel  =  msage %>% pivot_longer(cols=!c(date, month, year, day,wy), names_to="run", values_to="flow")
ggplot(subset(msagel, run == best$run), aes(date, flow)) + geom_line()



```

### high flow metrics
```{r}
source("compute_highflowmetrics_all.R")
res = msage %>% select(-date, -month, -day, -year, -wy ) %>% map_df(compute_highflowmetrics_all, o=sager$obs, month=msage$month, day=msage$day, year=msage$year, wy=msage$wy)


# interesting to look at range of metrics - could use this to decide on
# acceptable values
summary(res)


# graph range of performance measures
resl = res %>% pivot_longer(cols=everything(), names_to="metric", values_to="value")
ggplot(resl, aes(metric, value))+geom_boxplot()+facet_wrap(~metric, scales="free")

# try this
# assign an identifier to each row, use the same identify for columns of original streamflow data
# we can then use that to pick data
res$run = seq(from=1,to=nrow(res))
head(msage)
colnames(msage)=c(res$run, "date","month","year","day","wy")

# best & worst one
best = res[which.max(res$combined),]
worst = res[which.min(res$combined),]

msagel  =  msage %>% pivot_longer(cols=!c(date, month, year, day,wy), names_to="run", values_to="flow")

ggplot(subset(msagel, run == best$run), aes(date, flow)) + 
  geom_line() +
  labs(x = "Date",
       y = "Flow (mm/month)",
       title = "Monthly Aggregate Maximum Stream Flow for best model run") +
  theme_linedraw()
```

```{r}
msage = read.table("sagerm.txt", header=T)
# keep track of number of simulations (e.g results for each parameter set)
# use as a column names
nsim = ncol(msage)
snames = sprintf("S%d",seq(from=1, to=nsim))
colnames(msage)=snames
# lets say we know the start date from our earlier output
msage$date = sager$date
msage$month = sager$month
msage$year = sager$year
msage$day = sager$day
msage$wy = sager$wy
# lets add observed
msage = left_join(msage, sager[,c("obs","date")], by=c("date"))
head(msage)

source("nse.R")
source("relerr.R")
# subset for split sample calibration
short_msage = subset(msage, wy < 1975)
# compute performance measures for output from all parameters
res = short_msage %>% select(!c("date","month","year","day","wy","obs")) %>%
map_dbl(nse, short_msage$obs) 
# purrr function here! map_dbl will apply the function nse() to each column in our data frame against the observed and returns a vector
head(res)
# another example using our low flow statistics
# use apply to compute for all the data
source("compute_highflowmetrics_all.R")
res = short_msage %>% select(-date, -month, -day, -year, -wy, -obs ) %>%
map_df(compute_highflowmetrics_all, o=short_msage$obs, month=short_msage$month,
day=short_msage$day, year=short_msage$year, wy=short_msage$wy)

summary(res)

# we can add a row that links with simulation number
res$sim = snames
# graph range of performance measures
resl = res %>% pivot_longer(-sim, names_to="metric", values_to="value")
ggplot(resl, aes(metric, value))+geom_boxplot()+facet_wrap(~metric, scales="free")


# select the best one based on the combined metric
best = res[which.max(res$combined),]
# running the model forward
# so we can look at the full time series
# lets start with streamflow estimates from best performing parameter set
ggplot(msage, aes(date, msage[,best$sim])) + geom_line()+geom_line(aes(date, obs),
col="red")


# for comparison lets consider how worst and best parameters perform for subsequent simulations
# focusing specifically on April streamflow
worst = res[which.min(res$combined),]
compruns = msage %>% select(best$sim, worst$sim, date, obs, month, day, year, wy)
## post calibration
compruns_post = subset(compruns, wy > 1975)
compruns_mwy_post = compruns_post %>% select(-c(day,date, year)) %>% group_by(month, wy) %>%
summarize(across(everything(), mean))
compruns_mwy_post = compruns_mwy_post %>% pivot_longer(cols=!c(month,wy), names_to="sim",
values_to="flow")
post <- compruns_mwy_post %>% subset(month==4) %>% ggplot(aes(sim,flow ))+geom_boxplot() +labs(title = "Post-Calibration")

## pre calibration
compruns_pre = subset(compruns, wy < 1975)
compruns_mwy_pre = compruns_pre %>% select(-c(day,date, year)) %>% group_by(month, wy) %>%
summarize(across(everything(), mean))
compruns_mwy_pre = compruns_mwy_pre %>% pivot_longer(cols=!c(month,wy), names_to="sim",
values_to="flow")
pre <- compruns_mwy_pre %>% subset(month==4) %>% ggplot(aes(sim,flow ))+geom_boxplot() + labs(title = "Pre-Calibration")

pre + post
```


We chose to look at high flow (month with the highest flow rates) because high flow rates can contribute to steam erosion and damage in general. There was high variation in max flow across the months. We wanted to compute the percent error between stream flow observations and model runs. Since our maximum error is less than 50% (and is actually less than 0), we consider the model to be not acceptable and it cannot be helpful in estimating influences on overall stream flow. 
